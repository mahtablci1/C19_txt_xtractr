{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "root = '../../kaggle_data/'\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.extend(['within', 'what', 'how', 'eg', 'ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperLoader` class will load all papers for the challenge and provide an interface for us to obtain `DataFrames` to work with. The focus will be on:\n",
    "- Obtaining Paper title, Abstract, Body\n",
    "    - The text body is filtered to remove sections containing lots of citations and hyperlinks\n",
    "- Obtaining Authors, Journal of Publication, Publication Date and Publication Date\n",
    "- Obtaining journal ratings(H index) to potentially sort paper based on journal quality\n",
    "    - For the journal ratings, we use a list we obtained from **INSERT LINK HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperLoader():\n",
    "    \"\"\"\n",
    "    Loads, parses and merges metadata for papers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, no_bib=True):\n",
    "        \"\"\"\n",
    "        Initializes PaperLoader class to read all .json files from root_directory\n",
    "            \n",
    "            no_bib: if true, clean noisy sections with bibliographies\n",
    "            root_dir: root directory for papers\n",
    "        \"\"\"\n",
    "        self.ROOT_DIR = root_dir\n",
    "        self.JSON_FILES = glob.glob(f'{root}/**/*.json', recursive=True)\n",
    "        self.PAPERS_COLUMN = {\n",
    "            \"doc_id\": [None],\n",
    "            \"title\": [None],\n",
    "            \"abstract\": [None],\n",
    "            \"text_body\": [None]\n",
    "        }\n",
    "        self.PAPERS_DF = None\n",
    "        self.NO_BIB = no_bib\n",
    "\n",
    "    \n",
    "    def __clean_bib(self, body_text, thres):\n",
    "        \"\"\"\n",
    "        Removes sections with more than 5 URL/DOI/HTTP instances\n",
    "            \n",
    "            body_text: array of dictionaries for text_body\n",
    "            thres: number of hyperlinks tolerated before removal \n",
    "        \"\"\"\n",
    "        # Sometimes, the text body has duplicate sections consecutively.\n",
    "        merged_body = []\n",
    "        for segment in body_text:\n",
    "            # We will combine these duplicate sections\n",
    "            if len(merged_body) > 0:\n",
    "                if merged_body[-1]['section'] == segment['section']:\n",
    "                    merged_body[-1]['text'] += '\\n' + segment['text']\n",
    "                    continue\n",
    "            merged_body.append(segment)\n",
    "\n",
    "        merged_body = [\n",
    "            segment for segment in merged_body\n",
    "            if len(re.findall(\"(http|doi|www)\", segment['text'])) <= thres\n",
    "        ]\n",
    "        return merged_body\n",
    "\n",
    "\n",
    "    def create_paper_df(self):\n",
    "        \"\"\"\n",
    "        Creates a Pandas DataFrame from all json files in root_directory\n",
    "        Each json file represents a paper. \n",
    "        Features extracted are: doc_id, title, abstract, text_body\n",
    "        \"\"\"\n",
    "        df_list = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.JSON_FILES))):\n",
    "            file_name = self.JSON_FILES[i]\n",
    "            \n",
    "            #Initialize row for returned df. Each row represents a paper\n",
    "            row = {x: None for x in self.PAPERS_COLUMN}\n",
    "\n",
    "            with open(file_name) as json_data:\n",
    "                data = json.load(json_data)\n",
    "\n",
    "                row['doc_id'] = data['paper_id']\n",
    "                row['title'] = data['metadata']['title']\n",
    "                \n",
    "                # If title is empty, we skip the paper\n",
    "                if len(row['title']) <= 2:\n",
    "                    continue\n",
    "\n",
    "                # If a paper does not have an abstract of a body, we will skip it\n",
    "                if ('abstract' not in data or 'body_text' not in data):\n",
    "                    continue\n",
    "                else:\n",
    "                    # Now need all of the abstract. Put it all in\n",
    "                    # a list then use str.join() \n",
    "                    abstract_list = [abst['text'] for abst in data['abstract']]\n",
    "                    abstract = \"\\n \".join(abstract_list)\n",
    "\n",
    "                # Skip the paper if abstract is empty\n",
    "                if len(abstract) <= 2:\n",
    "                    continue\n",
    "\n",
    "                row['abstract'] = abstract\n",
    "\n",
    "                # And lastly the body of the text.\n",
    "                # These clauses check if the user wants to clean up references\n",
    "                if self.NO_BIB:\n",
    "                    body_list = self.__clean_bib(data['body_text'], 4)\n",
    "                else:\n",
    "                    body_list = [bt for bt in data['body_text']]\n",
    "\n",
    "                row['text_body'] = body_list\n",
    "\n",
    "                df_list.append(row)\n",
    "        # create final dataframe\n",
    "        self.PAPERS_DF = pd.DataFrame(df_list)\n",
    "\n",
    "\n",
    "    def merge_metadata(self, metadata = 'metadata.csv'):\n",
    "        \"\"\"\n",
    "            Joins paper information with information on journal for paper,\n",
    "            authors, doi and published date  \n",
    "                metadata: path to csv file containing metadata\n",
    "        \"\"\"\n",
    "        metadata_df = pd.read_csv(self.ROOT_DIR + metadata)\n",
    "        metadata_df = metadata_df.loc[:, \n",
    "                          ['sha', 'publish_time', 'authors', 'journal', 'doi']]\n",
    "        self.PAPERS_DF = self.PAPERS_DF.merge(metadata_df,\n",
    "                                              left_on='doc_id',\n",
    "                                              right_on='sha',\n",
    "                                              how='inner')\n",
    "\n",
    "    def merge_journals(self):\n",
    "        \"\"\"\n",
    "        Joins paper information with information on journal ratings\n",
    "        Important column: H_Index\n",
    "        \"\"\"\n",
    "        journal_df = pd.read_csv(root + 'scimagoj_2018.csv', sep=';')\n",
    "        papers_ratings_df = self.PAPERS_DF.merge(\n",
    "            journal_df.loc[:, ['Title', 'H index']],\n",
    "            left_on='journal',\n",
    "            right_on='Title',\n",
    "            how='left')\n",
    "        papers_ratings_df = papers_ratings_df.drop(\n",
    "            ['sha', 'Title'], axis=1).reset_index(drop=True)\n",
    "        self.PAPERS_DF = papers_ratings_df\n",
    "\n",
    "    def get_df(self):\n",
    "        \"\"\"\n",
    "        Returns processed dataframe\n",
    "        \"\"\"\n",
    "        self.PAPERS_DF = self.PAPERS_DF.dropna(\n",
    "            subset=['abstract', 'text_body'])\n",
    "        return self.PAPERS_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now parse the papers from our data(root) directory and store them in `papers_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2104f075137458b956266831bce9f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59311.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper_loader = PaperLoader(root)\n",
    "paper_loader.create_paper_df()\n",
    "paper_loader.merge_metadata()\n",
    "paper_loader.merge_journals()\n",
    "papers_df = paper_loader.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for covid-19 related papers released after 2019\n",
    "There is a lot of noise in this dataset due to information about other strains of coronavirus so we will select only the papers that are related to Covid-19. \n",
    "\n",
    "While the older papers may contain some important insight on the variance among the  different strains of coronavirus, for our purposes, we will only be looking at papers published on 2019 or later because that is when Covid-19 was first discovered in humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords for covid-19\n",
    "cov_list = [\n",
    "    'novel coronavi',\n",
    "    'covid',\n",
    "    'cov_2',\n",
    "    'cord-19',\n",
    "    'cord 19',\n",
    "    '2019-nCoV',\n",
    "    '2019 ncov',\n",
    "    '2019 cov',\n",
    "    'wuhan coronavi',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RelevantFilter` class will filter the dataframe from `PaperLoader` and filter for covid-19 papers published on 2019 or later. \n",
    "We will need to supply a list of covid-related keywords to filter from to the `constructor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevantFilter():\n",
    "    \n",
    "    def __init__(self, keywords, year='2019'):\n",
    "        \"\"\"\n",
    "        constructor for RelevantFilter\n",
    "            keywords: keywords to filter for\n",
    "            year: papers written before this year will be discarded\n",
    "        \"\"\"\n",
    "        self.KEYWORDS = keywords\n",
    "        self.YEAR = year\n",
    "\n",
    "    def extract_recent(self, df):\n",
    "        \"\"\"\n",
    "        extracts documents published on or after self.YEAR\n",
    "        \"\"\"\n",
    "        return df[df['publish_time'] >= self.YEAR]\n",
    "\n",
    "    def filter_papers(self, df):\n",
    "        \"\"\"\n",
    "        Filters for papers whose title have mention of \n",
    "        any of the terms in self.KEYWORDS\n",
    "        \"\"\"\n",
    "        pattern = re.compile('(' + \"|\".join(self.KEYWORDS) + ')',\n",
    "                                 re.IGNORECASE)\n",
    "        # We will filter for rows with one or more matches \n",
    "        # for title and covid keywords\n",
    "        df = df[df['title'].apply(lambda x: \n",
    "                                  len(pattern.findall(x)) >= 1\n",
    "                                  if x else False)]\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will filter through `papers_df` to get only covid-19 related papers in `covid_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filter = RelevantFilter(cov_list, '2019')\n",
    "covid_df = covid_filter.filter_papers(papers_df)\n",
    "covid_df = covid_filter.extract_recent(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(covid_df.head(2)['title'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Analysis (Phase 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go through the papers to extract and rank excerpts that contain relevant information about risk factors for covid-19. \n",
    "We will do this through an analysis of:\n",
    "\n",
    "- Risk factors for covid-19\n",
    "- Study designs\n",
    "    - We will use this to evaluate the quality of a paper's methodologies for our rankings\n",
    "- Outcomes\n",
    "    - We will incentivise excerpts to explicitly mention outcomes that we have found researchers look for(in our interviews)\n",
    "\n",
    "**Note**: The list of keywords were all obtained from a crowdsourced medical dictionary researchers had assembled. You can find more details [here](https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/edit#gid=1217643351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factors = [{\n",
    "    'name': 'smoking',\n",
    "    'pattern': 'smok'\n",
    "}, {\n",
    "    'name': 'diabetes',\n",
    "    'pattern': 'diabete'\n",
    "}, {\n",
    "    'name': 'pregnancy',\n",
    "    'pattern': 'pregnan'\n",
    "}, {\n",
    "    'name': 'tuberculosis',\n",
    "    'pattern': '(tubercul|mtb|\\btb[A-Za-z0-9]\\b)'\n",
    "}, {\n",
    "    'name': 'hypertension',\n",
    "    'pattern': 'hypertension'\n",
    "}, {\n",
    "    'name': 'cancer',\n",
    "    'pattern': 'cancer'\n",
    "}, {\n",
    "    'name': 'neonates',\n",
    "    'pattern': '(baby|neonate|enfant)'\n",
    "},\n",
    "    {\n",
    "    'name': 'liver disease',\n",
    "    'pattern': 'liver disease'\n",
    "},{\n",
    "    'name': 'COPD',\n",
    "    'pattern': 'COPD'\n",
    "},{\n",
    "    'name': 'pulmonary disease',\n",
    "    'pattern': 'pulm'\n",
    "},{\n",
    "    'name': 'race/ethnicity',\n",
    "    'pattern': 'ethnic'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_list = [\n",
    "    'mathemat', 'profil', 'cross sectional case control',\n",
    "    'matched case control', 'contact', 'surviv', 'tracing,', 'time to event',\n",
    "    'time-to-event', 'risk factor analysis', 'logistic regression',\n",
    "    'cross-sectional case-control', 'matched case-control',\n",
    "    'observational case series', 'time series analysis', 'survival analysis',\n",
    "    'investigati', 'model', 'outbreak', 'stochast', 'statist', 'analysi',\n",
    "    'experiment', 'excret', 'investig',\n",
    "    'retrospective cohort', 'cross-sectional case-control',\n",
    "    'cross sectional case control', 'prevalence survey', 'systematic review ',\n",
    "    'meta-analysis', 'meta analysis', 'matched case-control',\n",
    "    'matched case control', 'medical record review',\n",
    "    'observational case series', 'time series analysis',\n",
    "    'pseudo-randomized controlled', 'pseudo randomized controlled',\n",
    "    'randomized controlled', 'retrospective analysis', 'retrospective study',\n",
    "    'retrospective studies'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_list = [\n",
    "    'risk', 'range', 'duration', 'asymptomatic', 'infecti', 'reproducti',\n",
    "    'route', 'age', 'transmm'\n",
    "    'stratifi', 'period,', 'health', 'r0', 'shedd', 'viral'\n",
    "    'period', 'incub', 'generat', 'factor', 'interval,', 'serial'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperAnalyzer` class will take in a DataFrame of papers and then analyze each paper. \n",
    "The analysis is done with with its `analyze_risks()`, `analyze_designs()` and `analyze_outcomes()` methods that will analyze the risk factors, designs and outcomes respectively for excerpts in the paper. Finally, the `get_df()` method will return a new DataFrame with rankings for relevancy of excerpts. The rankings also factor in the `section` of the paper that the excerpt is from, with sections like **discussion** or **results** that seem to have pertinent, concise information ranked higher. Furthermore, these rankings are also normalized by the lenght of the excerpts\n",
    "\n",
    "*Note: These rankings for sections were determined through our interviews with epidimiologists.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperAnalyzer` helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_design(design_keyword):\n",
    "    \"\"\"\n",
    "    This helper function ranks study designs. So far we have\n",
    "    confirmed rankings for only three study designs, but this\n",
    "    data will be expanded and improved further with time as we \n",
    "    speak to more epidimiologists\n",
    "    \"\"\"\n",
    "    design_rankings = {\n",
    "        'meta': 10,\n",
    "        'random': 8,\n",
    "        'pseudo': 6,\n",
    "    }\n",
    "    current_ranking = -1\n",
    "    for key in design_rankings.keys():\n",
    "        if key in design_keyword.lower():\n",
    "            current_ranking = min(current_ranking, design_rankings[key])\n",
    "    \n",
    "    if current_ranking == -1:\n",
    "        current_ranking = 4\n",
    "    return current_ranking    \n",
    "\n",
    "def flatten(arr):\n",
    "    \"\"\"\n",
    "    Returns a single flat list from a list of lists\n",
    "    \"\"\"\n",
    "    return [item \n",
    "            for sublist in arr \n",
    "            for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAnalyzer():    \n",
    "    \"\"\"\n",
    "    Takes in a dataframe of papers and set it up for analysis\n",
    "    \"\"\"\n",
    "    # Setting up static constants\n",
    "    DEFAULT_RISKS = risk_factors\n",
    "    DEFAULT_DESIGNS = design_list\n",
    "    DEFAULT_OUTCOMES = outcome_list\n",
    "    \n",
    "    def __init__(self, parent_df):\n",
    "        \"\"\"\n",
    "        Explodes the passed dataframe on sections for more granular analysis\n",
    "        Sets up ranks to be updated later by methods\n",
    "        \"\"\"\n",
    "        # Section ratings\n",
    "        self.section_ratings = {\n",
    "                        'discus': 10,\n",
    "                        'concl': 10,\n",
    "                        'resul': 10,\n",
    "                        'analy': 9,\n",
    "                        'impli': 9,\n",
    "                        'valu': 9,\n",
    "                        'intro': 6\n",
    "                        }\n",
    "        \n",
    "        self.df = parent_df.explode('text_body')\n",
    "        # Extracting section headers\n",
    "        self.df['section'] = self.df['text_body'].apply(lambda x: \n",
    "                                                        x['section'] \n",
    "                                                        if type(x) == dict \n",
    "                                                        else None)\n",
    "        # Extracting section texts\n",
    "        self.df['text_body'] = self.df['text_body'].apply(lambda x:\n",
    "                                                          x['text'] \n",
    "                                                          if type(x) == dict \n",
    "                                                          else None)\n",
    "        # Dropping rows where section text is empty\n",
    "        self.df = self.df[self.df['text_body'].notna()]\n",
    "        self.df['total_rank'] = 0\n",
    "        # TQDM is used for progress bars\n",
    "        tqdm.pandas()\n",
    "\n",
    "    def analyze_risks(self, risk_factors):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for risk factors and returns a report df\n",
    "        with columns has_{risk_factor}?, {risk_factor}_count, \n",
    "        {risk_factor}_in_title and updates {total_rank} for each row.\n",
    "        The match_indices column is produced for ease of visualization\n",
    "        in the web app.\n",
    "        \"\"\"\n",
    "        if risk_factors == None:\n",
    "            risk_factors = PaperAnalyzer.DEFAULT_RISKS\n",
    "        \n",
    "        if type(risk_factors[0]) == dict:\n",
    "            patterns = [risk['pattern'] for risk in risk_factors]\n",
    "        elif type(risk_factors[0]) == str:\n",
    "            patterns = [risk for risk in risk_factors]\n",
    "        \n",
    "        self.df = self.df[self.df['text_body'].apply(lambda x:\n",
    "                                                    any(re.compile(pattern, re.IGNORECASE).findall(x)\n",
    "                                                       for pattern in patterns)\n",
    "                                                    )]\n",
    "        self.df['risk_factors'] = [[]] * len(self.df)\n",
    "        self.df['match_indices'] = [[]] * len(self.df)\n",
    "        for i in tqdm(range(len(risk_factors))):\n",
    "            factor = risk_factors[i]\n",
    "            if type(factor) == dict:\n",
    "                name = factor['name']\n",
    "                pattern = re.compile(factor['pattern'], re.IGNORECASE)\n",
    "            elif type(factor) == str:\n",
    "                name = factor\n",
    "                pattern = re.compile(factor, re.IGNORECASE)\n",
    "    \n",
    "            self.df['_matches'] = self.df['text_body'].apply(lambda x: \n",
    "                                                                      [(m.start(), m.group()) \n",
    "                                                                       for m in pattern.finditer(x)])\n",
    "            \n",
    "            self.df[name + '_count'] = self.df['_matches'].apply(lambda x: len(x))\n",
    "            self.df['has_' + name + '?'] = self.df[name + '_count'].apply(lambda x: x > 0)\n",
    "            self.df[name + '_in_title'] = self.df['title'].apply(lambda x:\n",
    "                                                                         len(pattern.findall(x)) > 0)\n",
    "            self.df[name + '_count'] = self.df.apply(lambda x:\n",
    "                                                             x[name + '_count'] + 10\n",
    "                                                            if x[name + '_in_title'] \n",
    "                                                             else x[name + '_count'],\n",
    "                                                            axis=1)\n",
    "            self.df['total_rank'] += 2 * self.df[name + '_count']\n",
    "            \n",
    "            self.df['risk_factors'] = self.df.apply(lambda x: \n",
    "                                    x['risk_factors'] + [name] if x['has_' + name + '?']\n",
    "                                    else x['risk_factors'],\n",
    "                                   axis=1)\n",
    "            self.df['match_indices'] = self.df.apply(lambda x: \n",
    "                                    x['match_indices'] + [n[0] for n in x['_matches']] if x['has_' + name + '?']\n",
    "                                    else x['match_indices'],\n",
    "                                   axis=1)\n",
    "            self.df.drop('_matches', axis=1, inplace=True)\n",
    "            \n",
    "\n",
    "    def analyze_designs(self, design_list):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for study designs and returns a report df \n",
    "        with 'design' and 'design_rank'. 'design_rank' is decided upon from the \n",
    "        input in crowdsourced medical dictionary.\n",
    "        \"\"\"\n",
    "        if design_list == None:\n",
    "            design_list = PaperAnalyzer.DEFAULT_DESIGNS\n",
    "        self.df['design'] = self.df['text_body'].progress_apply(lambda x:\n",
    "                                                                      [re.findall(des, x, re.IGNORECASE) \n",
    "                                                                       for des in design_list])\n",
    "        self.df['design_rank'] = self.df['design'].apply(lambda x:\n",
    "                                                                len(x))\n",
    "        self.df['design_rank'] += self.df['design'].apply(lambda x: rank_design(' '.join(flatten(x))))\n",
    "        self.df['total_rank'] += self.df['design_rank']\n",
    "\n",
    "    def analyze_outcomes(self, outcomes):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for outcomes and returns a report df \n",
    "        with 'outcomes' and 'outcome_rank'. 'outcome_rank' is decided upon \n",
    "        by the frequency of mentions of outcomes in the excerpt\n",
    "        \"\"\"\n",
    "        \n",
    "        if outcomes == None:\n",
    "            outcomes = PaperAnalyzer.DEFAULT_OUTCOMES\n",
    "        self.df['outcomes'] = self.df['text_body'].progress_apply(lambda x:\n",
    "                                                                        [re.findall(outcome, x, re.IGNORECASE)\n",
    "                                                                         for outcome in outcomes])\n",
    "        self.df['outcome_rank'] = self.df['outcomes'].apply(lambda x: len(x))\n",
    "        self.df['total_rank'] += 2* self.df['outcome_rank']\n",
    "\n",
    "    def perform_analysis(self, risk_factors, design_list=None, outcomes=None):\n",
    "        \"\"\"\n",
    "        This function is a wrapper function that provides interface\n",
    "        to conduct analysis on all of risk factors, study designs and\n",
    "        outcomes. Users may specify their own design_list or outcomes. If not,\n",
    "        the default is used.\n",
    "        \"\"\"\n",
    "        print(\"Analyzing risks\")\n",
    "        self.analyze_risks(risk_factors)\n",
    "        print(\"Analyzing study designs\")\n",
    "        self.analyze_designs(design_list)\n",
    "        print(\"Analyzing outcomes\")\n",
    "        self.analyze_outcomes(outcomes)\n",
    "\n",
    "    def get_df(self, risk_factor=None):\n",
    "        \"\"\"\n",
    "        Applies section ratings, updates total ratings and returns reporting df\n",
    "            risk_factor: if specified, the returned df will only have excerpts\n",
    "                            that mention this risk factor\n",
    "        \"\"\"\n",
    "        self.df['section_rank'] = self.df['section'].apply(lambda x: self.section_ratings[x] \n",
    "                                                           if x in self.section_ratings else 5)\n",
    "        self.df['total_rank'] += self.df['section_rank']\n",
    "        \n",
    "        # Normalizing total rank for length of excerpts\n",
    "        self.df['total_rank'] = self.df.apply(lambda x: x['total_rank']\n",
    "                                                     /(len(word_tokenize(x['text_body'])))\n",
    "                                              , axis=1)\n",
    "        if risk_factor:\n",
    "            if not self.__ANALYZED_RISKS:\n",
    "                raise ValueError(self.__ERROR_MESSAGE)\n",
    "            return self.df[self.df['has_' + risk_factor +\n",
    "                                                   '?'] == True]\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_analysis = PaperAnalyzer(covid_df)\n",
    "covid_analysis.analyze_risks(risk_factors)\n",
    "covid_analysis.analyze_designs(design_list)\n",
    "covid_analysis.analyze_outcomes(outcome_list)\n",
    "enriched_covid_df = covid_analysis.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df.sort_values(by='total_rank', ascending=False).iloc[1]['text_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df.to_json(\"../../enriched_covid_df.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This marks the end of phase 1. The resulting dataframe will be stored as a json to be served by the web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Search (Phase 2)\n",
    "We will extend the capabilities from the `PaperAnalyzer` class and attempt to answer some questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Question` class will decompose and resolve a question about risk factors.\n",
    "The result will then be piped to an instance of `PaperAnalyzer` to conduct similar analysis. Users will be able to specify their own list of outcomes. If not specified, the default set of outcomes will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    \"\"\"\n",
    "    The purpose of this class is to resolve a question for \n",
    "    keyword searching\n",
    "    \"\"\"\n",
    "    def __init__(self, question, design_list=None, outcomes=None):\n",
    "        \"\"\"\n",
    "        The constuctor does most of the method-calling for question resolution\n",
    "        \"\"\"\n",
    "        self.DESIGN_LIST = design_list\n",
    "        self.OUTCOMES = outcomes\n",
    "        self.RISK = question\n",
    "        self.risk_factors = None\n",
    "        self.design_list = None\n",
    "        self.outcome_list = None\n",
    "        self.__resolve_question()\n",
    "        if design_list:\n",
    "            self.__resolve_design()\n",
    "        if outcomes:\n",
    "            self.__resolve_outcomes()\n",
    "\n",
    "    def __question_tokenize(self, sent):\n",
    "        \"\"\"\n",
    "        Cleans the question string\n",
    "        \"\"\"\n",
    "        abbvr_pattern = re.compile('(e.g.|i.e.)')\n",
    "        sent = abbvr_pattern.sub('', sent)\n",
    "        remove_punct_dict = {key: \" \" for key in string.punctuation}\n",
    "        remove_punct_dict['.'] = ''\n",
    "        remove_punct = str.maketrans(remove_punct_dict)\n",
    "        sent = sent.translate(remove_punct)\n",
    "        return sent.replace('R', 'R0').replace('-', ' ')\n",
    "\n",
    "    def __resolve_question(self):\n",
    "        \"\"\"\n",
    "        stems and removes irreleavnt words from questions\n",
    "        to create keywords for keyword analysis\n",
    "        \"\"\"\n",
    "        subquestion = self.RISK\n",
    "        sub_q = self.__question_tokenize(subquestion)\n",
    "        keywords = set([\n",
    "            stemmer.stem(word) for word in word_tokenize(sub_q)\n",
    "            if word.lower() not in stop_words and 'cov' not in word.lower()\n",
    "            and word.lower().islower()  #This checks and removes numbers\n",
    "        ])\n",
    "        self.risk_factors = list(keywords)\n",
    "\n",
    "    def __resolve_design(self):\n",
    "        \"\"\"\n",
    "        Resolves study designs to allow for study-design evaluation\n",
    "        \"\"\"\n",
    "        design_keys = self.DESIGN_LIST.split(\",\")\n",
    "        self.design_list = list(set(design_keys))\n",
    "\n",
    "    def __resolve_outcomes(self):\n",
    "        \"\"\"\n",
    "        Resolves outcomes to allow for outcome evaluation\n",
    "        \"\"\"\n",
    "        outcome_keys = self.__question_tokenize(self.OUTCOMES)\n",
    "        outcome_keys = set([\n",
    "            stemmer.stem(word) for word in word_tokenize(outcome_keys)\n",
    "            if word.lower() not in stop_words\n",
    "            and word.lower().islower()  #This checks and removes numbers\n",
    "        ])\n",
    "        self.outcome_list = list(outcome_keys)\n",
    "\n",
    "    def get_keywords(self):\n",
    "        \"\"\"\n",
    "        Returns keywords from earlier methods\n",
    "        \"\"\"\n",
    "        result = {'risk': None, 'design': None, 'outcome': None}\n",
    "        result['risk'] = self.risk_factors\n",
    "        if self.design_list:\n",
    "            result['design'] = self.design_list\n",
    "        if self.outcome_list:\n",
    "            result['outcome'] = self.outcome_list\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_question(df, question):\n",
    "    \"\"\"\n",
    "    Function to take in a Question instance and a \n",
    "    dataframe with covid-excerpts to perform \n",
    "    evaluation and rankings on information relevancy\n",
    "    \"\"\"\n",
    "    reference_df = PaperAnalyzer(df)\n",
    "    keys = question.get_keywords()\n",
    "    reference_df.perform_analysis(keys['risk'], keys['design'],\n",
    "                                  keys['outcome'])\n",
    "    return reference_df.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be trying out the question answering pipeline now with a few questions from the aforementionned [medical dictionary](https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/edit#gid=1217643351)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_sheet(url, sheet_name):\n",
    "    response=requests.get(url=url)\n",
    "    sample_file = io.BytesIO(response.content)\n",
    "    df = pd.read_excel(sample_file, sheet_name = sheet_name)\n",
    "    return df\n",
    "\n",
    "dict_url = 'https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/export?format=xlsx&id=1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E'\n",
    "questions_df = get_google_sheet(dict_url, 'sub.question.matching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking a sample question for analysis\n",
    "ques = questions_df.iloc[127]['Subquestion']\n",
    "ques = sent_tokenize(ques)[0]\n",
    "ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designs recommended for sample question\n",
    "des = questions_df.iloc[127]['Design.list']\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcomes recommended for sample question\n",
    "outc = questions_df.iloc[127]['Outcome.list']\n",
    "outc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = analyze_question(covid_df, Question(ques, des, outc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now look at the 5 most relevant excerpts to the question we picked earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(report_df.sort_values(by='total_rank', ascending = False).iloc[i]['text_body'])\n",
    "    print(\"-----------------------------\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv11568a5b709c405b925f37b6b0b6dbdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
