{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ppandarallel\n",
    "pandarallel.initialize()\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "root = '../../kaggle_data/'\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.extend(['within', 'what', 'how', 'eg', 'ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperLoader` class will load all papers for the challenge and provide an interface for us to obtain `DataFrames` to work with. The focus will be on:\n",
    "- Obtaining Paper title, Abstract, Body\n",
    "    - The text body is filtered to remove sections containing lots of citations and hyperlinks\n",
    "- Obtaining Authors, Journal of Publication, Publication Date and Publication Date\n",
    "- Obtaining journal ratings(H index) to potentially sort paper based on journal quality\n",
    "    - For the journal ratings, we use a list we obtained from **INSERT LINK HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperLoader():\n",
    "    \"\"\"\n",
    "    Loads, parses and merges metadata for papers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, no_bib=True):\n",
    "        \"\"\"\n",
    "        Initializes PaperLoader class to read all .json files from root_directory\n",
    "            \n",
    "            no_bib: if true, clean noisy sections with bibliographies\n",
    "            root_dir: root directory for papers\n",
    "        \"\"\"\n",
    "        self.ROOT_DIR = root_dir\n",
    "        self.JSON_FILES = glob.glob(f'{root}/**/*.json', recursive=True)\n",
    "        self.PAPERS_COLUMN = {\n",
    "            \"doc_id\": [None],\n",
    "            \"title\": [None],\n",
    "            \"abstract\": [None],\n",
    "            \"text_body\": [None]\n",
    "        }\n",
    "        self.PAPERS_DF = None\n",
    "        self.NO_BIB = no_bib\n",
    "\n",
    "    \n",
    "    def __clean_bib(self, body_text, thres):\n",
    "        \"\"\"\n",
    "        Removes sections with more than 5 URL/DOI/HTTP instances\n",
    "            \n",
    "            body_text: array of dictionaries for text_body\n",
    "            thres: number of hyperlinks tolerated before removal \n",
    "        \"\"\"\n",
    "        # Sometimes, the text body has duplicate sections consecutively.\n",
    "        merged_body = []\n",
    "        for segment in body_text:\n",
    "            # We will combine these duplicate sections\n",
    "            if len(merged_body) > 0:\n",
    "                if merged_body[-1]['section'] == segment['section']:\n",
    "                    merged_body[-1]['text'] += '\\n' + segment['text']\n",
    "                    continue\n",
    "            merged_body.append(segment)\n",
    "\n",
    "        merged_body = [\n",
    "            segment for segment in merged_body\n",
    "            if len(re.findall(\"(http|doi|www)\", segment['text'])) <= thres\n",
    "        ]\n",
    "        return merged_body\n",
    "\n",
    "\n",
    "    def create_paper_df(self):\n",
    "        \"\"\"\n",
    "        Creates a Pandas DataFrame from all json files in root_directory\n",
    "        Each json file represents a paper. \n",
    "        Features extracted are: doc_id, title, abstract, text_body\n",
    "        \"\"\"\n",
    "        df_list = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.JSON_FILES))):\n",
    "            file_name = self.JSON_FILES[i]\n",
    "            \n",
    "            #Initialize row for returned df. Each row represents a paper\n",
    "            row = {x: None for x in self.PAPERS_COLUMN}\n",
    "\n",
    "            with open(file_name) as json_data:\n",
    "                data = json.load(json_data)\n",
    "\n",
    "                row['doc_id'] = data['paper_id']\n",
    "                row['title'] = data['metadata']['title']\n",
    "                \n",
    "                # If title is empty, we skip the paper\n",
    "                if len(row['title']) <= 2:\n",
    "                    continue\n",
    "\n",
    "                # If a paper does not have an abstract of a body, we will skip it\n",
    "                if ('abstract' not in data or 'body_text' not in data):\n",
    "                    continue\n",
    "                else:\n",
    "                    # Now need all of the abstract. Put it all in\n",
    "                    # a list then use str.join() \n",
    "                    abstract_list = [abst['text'] for abst in data['abstract']]\n",
    "                    abstract = \"\\n \".join(abstract_list)\n",
    "\n",
    "                # Skip the paper if abstract is empty\n",
    "                if len(abstract) <= 2:\n",
    "                    continue\n",
    "\n",
    "                row['abstract'] = abstract\n",
    "\n",
    "                # And lastly the body of the text.\n",
    "                # These clauses check if the user wants to clean up references\n",
    "                if self.NO_BIB:\n",
    "                    body_list = self.__clean_bib(data['body_text'], 4)\n",
    "                else:\n",
    "                    body_list = [bt for bt in data['body_text']]\n",
    "\n",
    "                row['text_body'] = body_list\n",
    "\n",
    "                df_list.append(row)\n",
    "        # create final dataframe\n",
    "        self.PAPERS_DF = pd.DataFrame(df_list)\n",
    "\n",
    "\n",
    "    def merge_metadata(self, metadata = 'metadata.csv'):\n",
    "        \"\"\"\n",
    "            Joins paper information with information on journal for paper,\n",
    "            authors, doi and published date  \n",
    "                metadata: path to csv file containing metadata\n",
    "        \"\"\"\n",
    "        metadata_df = pd.read_csv(self.ROOT_DIR + metadata)\n",
    "        metadata_df = metadata_df.loc[:, \n",
    "                          ['sha', 'publish_time', 'authors', 'journal', 'doi']]\n",
    "        self.PAPERS_DF = self.PAPERS_DF.merge(metadata_df,\n",
    "                                              left_on='doc_id',\n",
    "                                              right_on='sha',\n",
    "                                              how='inner')\n",
    "\n",
    "    def merge_journals(self):\n",
    "        \"\"\"\n",
    "        Joins paper information with information on journal ratings\n",
    "        Important column: H_Index\n",
    "        \"\"\"\n",
    "        journal_df = pd.read_csv(root + 'scimagoj_2018.csv', sep=';')\n",
    "        papers_ratings_df = self.PAPERS_DF.merge(\n",
    "            journal_df.loc[:, ['Title', 'H index']],\n",
    "            left_on='journal',\n",
    "            right_on='Title',\n",
    "            how='left')\n",
    "        papers_ratings_df = papers_ratings_df.drop(\n",
    "            ['sha', 'Title'], axis=1).reset_index(drop=True)\n",
    "        self.PAPERS_DF = papers_ratings_df\n",
    "\n",
    "    def get_df(self):\n",
    "        \"\"\"\n",
    "        Returns processed dataframe\n",
    "        \"\"\"\n",
    "        self.PAPERS_DF = self.PAPERS_DF.dropna(\n",
    "            subset=['abstract', 'text_body'])\n",
    "        return self.PAPERS_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now parse the papers from our data(root) directory and store them in `papers_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434069cb795b4887944cb877ab013be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59311.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paper_loader = PaperLoader(root)\n",
    "paper_loader.create_paper_df()\n",
    "paper_loader.merge_metadata()\n",
    "paper_loader.merge_journals()\n",
    "papers_df = paper_loader.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306ef95a3a91e13a93bcc37fb2c509b67c0b5640</td>\n",
       "      <td>A Novel Approach for a Novel Pathogen: using a...</td>\n",
       "      <td>Thousands of people in the United States have ...</td>\n",
       "      <td>[{'text': 'The 2019 novel coronavirus (SARS-Co...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...</td>\n",
       "      <td>Clin Infect Dis</td>\n",
       "      <td>10.1093/cid/ciaa256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6599ebbef3d868afac9daa4f80fa075675cf03bc</td>\n",
       "      <td>International aviation emissions to 2025: Can ...</td>\n",
       "      <td>International aviation is growing rapidly, res...</td>\n",
       "      <td>[{'text': 'Sixty years ago, civil aviation was...</td>\n",
       "      <td>2009-01-31</td>\n",
       "      <td>Macintosh, Andrew; Wallace, Lailey</td>\n",
       "      <td>Energy Policy</td>\n",
       "      <td>10.1016/j.enpol.2008.08.029</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doc_id  \\\n",
       "0  306ef95a3a91e13a93bcc37fb2c509b67c0b5640   \n",
       "1  6599ebbef3d868afac9daa4f80fa075675cf03bc   \n",
       "\n",
       "                                               title  \\\n",
       "0  A Novel Approach for a Novel Pathogen: using a...   \n",
       "1  International aviation emissions to 2025: Can ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Thousands of people in the United States have ...   \n",
       "1  International aviation is growing rapidly, res...   \n",
       "\n",
       "                                           text_body publish_time  \\\n",
       "0  [{'text': 'The 2019 novel coronavirus (SARS-Co...   2020-03-12   \n",
       "1  [{'text': 'Sixty years ago, civil aviation was...   2009-01-31   \n",
       "\n",
       "                                             authors          journal  \\\n",
       "0  Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...  Clin Infect Dis   \n",
       "1                 Macintosh, Andrew; Wallace, Lailey    Energy Policy   \n",
       "\n",
       "                           doi  H index  \n",
       "0          10.1093/cid/ciaa256      NaN  \n",
       "1  10.1016/j.enpol.2008.08.029    178.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25312, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for covid-19 related papers released after 2019\n",
    "There is a lot of noise in this dataset due to information about other strains of coronavirus so we will select only the papers that are related to Covid-19. \n",
    "\n",
    "While the older papers may contain some important insight on the variance among the  different strains of coronavirus, for our purposes, we will only be looking at papers published on 2019 or later because that is when Covid-19 was first discovered in humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords for covid-19\n",
    "cov_list = [\n",
    "    'novel coronavi',\n",
    "    'covid',\n",
    "    'cov_2',\n",
    "    'cord-19',\n",
    "    'cord 19',\n",
    "    '2019-nCoV',\n",
    "    '2019 ncov',\n",
    "    '2019 cov',\n",
    "    'wuhan coronavi',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RelevantFilter` class will filter the dataframe from `PaperLoader` and filter for covid-19 papers published on 2019 or later. \n",
    "We will need to supply a list of covid-related keywords to filter from to the `constructor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevantFilter():\n",
    "    \n",
    "    def __init__(self, keywords, year='2019'):\n",
    "        \"\"\"\n",
    "        constructor for RelevantFilter\n",
    "            keywords: keywords to filter for\n",
    "            year: papers written before this year will be discarded\n",
    "        \"\"\"\n",
    "        self.KEYWORDS = keywords\n",
    "        self.YEAR = year\n",
    "\n",
    "    def extract_recent(self, df):\n",
    "        \"\"\"\n",
    "        extracts documents published on or after self.YEAR\n",
    "        \"\"\"\n",
    "        return df[df['publish_time'] >= self.YEAR]\n",
    "\n",
    "    def filter_papers(self, df):\n",
    "        \"\"\"\n",
    "        Filters for papers whose title have mention of \n",
    "        any of the terms in self.KEYWORDS\n",
    "        \"\"\"\n",
    "        pattern = re.compile('(' + \"|\".join(self.KEYWORDS) + ')',\n",
    "                                 re.IGNORECASE)\n",
    "        # We will filter for rows with one or more matches \n",
    "        # for title and covid keywords\n",
    "        df = df[df['title'].apply(lambda x: \n",
    "                                  len(pattern.findall(x)) >= 1\n",
    "                                  if x else False)]\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will filter through `papers_df` to get only covid-19 related papers in `covid_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filter = RelevantFilter(cov_list, '2019')\n",
    "covid_df = covid_filter.filter_papers(papers_df)\n",
    "covid_df = covid_filter.extract_recent(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306ef95a3a91e13a93bcc37fb2c509b67c0b5640</td>\n",
       "      <td>A Novel Approach for a Novel Pathogen: using a...</td>\n",
       "      <td>Thousands of people in the United States have ...</td>\n",
       "      <td>[{'text': 'The 2019 novel coronavirus (SARS-Co...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...</td>\n",
       "      <td>Clin Infect Dis</td>\n",
       "      <td>10.1093/cid/ciaa256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doc_id  \\\n",
       "0  306ef95a3a91e13a93bcc37fb2c509b67c0b5640   \n",
       "\n",
       "                                               title  \\\n",
       "0  A Novel Approach for a Novel Pathogen: using a...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Thousands of people in the United States have ...   \n",
       "\n",
       "                                           text_body publish_time  \\\n",
       "0  [{'text': 'The 2019 novel coronavirus (SARS-Co...   2020-03-12   \n",
       "\n",
       "                                             authors          journal  \\\n",
       "0  Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...  Clin Infect Dis   \n",
       "\n",
       "                   doi  H index  \n",
       "0  10.1093/cid/ciaa256      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Novel Approach for a Novel Pathogen: using a home assessment team to evaluate patients for 2019 novel coronavirus (SARS-CoV-2)',\n",
       " 'Modeling the dynamics of novel coronavirus (2019-nCov) with fractional derivative']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(covid_df.head(2)['title'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Analysis (Phase 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now go through the papers to extract and rank excerpts that contain relevant information about risk factors for covid-19. \n",
    "We will do this through an analysis of:\n",
    "\n",
    "- Risk factors for covid-19\n",
    "- Study designs\n",
    "    - We will use this to evaluate the quality of a paper's methodologies for our rankings\n",
    "- Outcomes\n",
    "    - We will incentivise excerpts to explicitly mention outcomes that we have found researchers look for(in our interviews)\n",
    "- Fatality\n",
    "    - We have determined that information on mortality and fatality would be of high value to researcehrs, and rightly so.\n",
    "\n",
    "**Note**: The list of keywords were all obtained from a crowdsourced medical dictionary researchers had assembled. You can find more details [here](https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/edit#gid=1217643351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factors = [{\n",
    "    'name': 'smoking',\n",
    "    'pattern': 'smok'\n",
    "}, {\n",
    "    'name': 'diabetes',\n",
    "    'pattern': 'diabete'\n",
    "}, {\n",
    "    'name': 'pregnancy',\n",
    "    'pattern': 'pregnan'\n",
    "}, {\n",
    "    'name': 'tuberculosis',\n",
    "    'pattern': '(tubercul|mtb|\\btb[A-Za-z0-9]\\b)'\n",
    "}, {\n",
    "    'name': 'hypertension',\n",
    "    'pattern': 'hypertension'\n",
    "}, {\n",
    "    'name': 'cancer',\n",
    "    'pattern': 'cancer'\n",
    "}, {\n",
    "    'name': 'neonates',\n",
    "    'pattern': '(baby|neonate|enfant)'\n",
    "},\n",
    "    {\n",
    "    'name': 'liver disease',\n",
    "    'pattern': 'liver disease'\n",
    "},{\n",
    "    'name': 'COPD',\n",
    "    'pattern': 'COPD'\n",
    "},{\n",
    "    'name': 'pulmonary disease',\n",
    "    'pattern': 'pulm'\n",
    "},{\n",
    "    'name': 'race/ethnicity',\n",
    "    'pattern': 'ethnic'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_list = [\n",
    "    'mathemat', 'profil', 'cross sectional case control',\n",
    "    'matched case control', 'contact', 'surviv', 'tracing,', 'time to event',\n",
    "    'time-to-event', 'risk factor analysis', 'logistic regression',\n",
    "    'cross-sectional case-control', 'matched case-control',\n",
    "    'observational case series', 'time series analysis', 'survival analysis',\n",
    "    'investigati', 'model', 'outbreak', 'stochast', 'statist', 'analysi',\n",
    "    'experiment', 'excret', 'investig',\n",
    "    'retrospective cohort', 'cross-sectional case-control',\n",
    "    'cross sectional case control', 'prevalence survey', 'systematic review ',\n",
    "    'meta-analysis', 'meta analysis', 'matched case-control',\n",
    "    'matched case control', 'medical record review',\n",
    "    'observational case series', 'time series analysis',\n",
    "    'pseudo-randomized controlled', 'pseudo randomized controlled',\n",
    "    'randomized controlled', 'retrospective analysis', 'retrospective study',\n",
    "    'retrospective studies'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_list = [\n",
    "    'risk', 'range', 'duration', 'asymptomatic', 'infecti', 'reproducti',\n",
    "    'route', 'age', 'transmm'\n",
    "    'stratifi', 'period,', 'health', 'r0', 'shedd', 'viral'\n",
    "    'period', 'incub', 'generat', 'factor', 'interval,', 'serial'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatality_list = ['icu', 'fatal', 'death', 'die', 'dead', 'dying', 'mortal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next cell will contain the default coeffecients for the algorithm's prioritization of different features. These coeffecients are a work in progress and we seek to constantly improve them with more expert feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_weights= {\n",
    "    'risk': 2,\n",
    "    'design': 1,\n",
    "    'outcome': 2,\n",
    "    'fatality': 1,    \n",
    "    'inverse_length': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperAnalyzer` class will take in a DataFrame of papers and then analyze each paper. \n",
    "The analysis is done with with its `analyze_risks()`, `analyze_designs()` and `analyze_outcomes()` methods that will analyze the risk factors, designs and outcomes respectively for excerpts in the paper. Finally, the `get_df()` method will return a new DataFrame with rankings for relevancy of excerpts. The rankings also factor in the `section` of the paper that the excerpt is from, with sections like **discussion** or **results** that seem to have pertinent, concise information ranked higher. Furthermore, these rankings are also normalized by the lenght of the excerpts\n",
    "\n",
    "*Note: These rankings for sections were determined through our interviews with epidimiologists.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperAnalyzer` helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_design(design_keyword):\n",
    "    \"\"\"\n",
    "    This helper function ranks study designs. So far we have\n",
    "    confirmed rankings for only three study designs, but this\n",
    "    data will be expanded and improved further with time as we \n",
    "    speak to more epidimiologists\n",
    "    \"\"\"\n",
    "    design_rankings = {\n",
    "        'meta': 10,\n",
    "        'random': 8,\n",
    "        'pseudo': 6,\n",
    "    }\n",
    "    current_ranking = -1\n",
    "    for key in design_rankings.keys():\n",
    "        if key in design_keyword.lower():\n",
    "            current_ranking = min(current_ranking, design_rankings[key])\n",
    "    \n",
    "    if current_ranking == -1:\n",
    "        current_ranking = 4\n",
    "    return current_ranking    \n",
    "\n",
    "def flatten(arr):\n",
    "    \"\"\"\n",
    "    Returns a single flat list from a list of lists\n",
    "    \"\"\"\n",
    "    return [item \n",
    "            for sublist in arr \n",
    "            for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAnalyzer():    \n",
    "    \"\"\"\n",
    "    Takes in a dataframe of papers and set it up for analysis\n",
    "    \"\"\"\n",
    "    # Setting up static constants\n",
    "    DEFAULT_RISKS = risk_factors\n",
    "    DEFAULT_DESIGNS = design_list\n",
    "    DEFAULT_OUTCOMES = outcome_list\n",
    "    DEFAULT_FATAL = fatality_list\n",
    "    DEFAULT_WEIGHTS = evaluation_weights\n",
    "    \n",
    "    def __init__(self, parent_df, weights = None):\n",
    "        \"\"\"\n",
    "        Explodes the passed dataframe on sections for more granular analysis\n",
    "        Sets up ranks to be updated later by methods. Client can supply their\n",
    "        own dictionary of weights for different features.\n",
    "        \"\"\"\n",
    "        # Section ratings\n",
    "        self.section_ratings = {\n",
    "                        'discus': 10,\n",
    "                        'concl': 10,\n",
    "                        'resul': 10,\n",
    "                        'analy': 9,\n",
    "                        'impli': 9,\n",
    "                        'valu': 9,\n",
    "                        'intro': 6\n",
    "                        }\n",
    "        \n",
    "        self.df = parent_df.explode('text_body')\n",
    "        # Extracting section headers\n",
    "        self.df['section'] = self.df['text_body'].apply(lambda x: \n",
    "                                                        x['section'] \n",
    "                                                        if type(x) == dict \n",
    "                                                        else None)\n",
    "        # Extracting section texts\n",
    "        self.df['text_body'] = self.df['text_body'].apply(lambda x:\n",
    "                                                          x['text'] \n",
    "                                                          if type(x) == dict \n",
    "                                                          else None)\n",
    "        # Dropping rows where section text is empty\n",
    "        self.df = self.df[self.df['text_body'].notna()]\n",
    "        self.df['total_rank'] = 0\n",
    "        if weights:\n",
    "            self.weights = weights\n",
    "        else:\n",
    "            self.weights = PaperAnalyzer.DEFAULT_WEIGHTS\n",
    "        # TQDM is used for progress bars\n",
    "        tqdm.pandas()\n",
    "\n",
    "    def analyze_risks(self, risk_factors):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for risk factors and returns a report df\n",
    "        with columns has_{risk_factor}?, {risk_factor}_count, \n",
    "        {risk_factor}_in_title and updates {total_rank} for each row.\n",
    "        The match_indices column is produced for ease of visualization\n",
    "        in the web app.\n",
    "        \"\"\"\n",
    "        if risk_factors == None:\n",
    "            risk_factors = PaperAnalyzer.DEFAULT_RISKS\n",
    "        \n",
    "        if type(risk_factors[0]) == dict:\n",
    "            patterns = [risk['pattern'] for risk in risk_factors]\n",
    "        elif type(risk_factors[0]) == str:\n",
    "            patterns = [risk for risk in risk_factors]\n",
    "        \n",
    "        self.df = self.df[self.df['text_body'].apply(lambda x:\n",
    "                                                    any(re.compile(pattern, re.IGNORECASE).findall(x)\n",
    "                                                       for pattern in patterns)\n",
    "                                                    )]\n",
    "        self.df['risk_factors'] = [[]] * len(self.df)\n",
    "        self.df['match_indices'] = [[]] * len(self.df)\n",
    "        for i in tqdm(range(len(risk_factors))):\n",
    "            factor = risk_factors[i]\n",
    "            if type(factor) == dict:\n",
    "                name = factor['name']\n",
    "                pattern = re.compile(factor['pattern'], re.IGNORECASE)\n",
    "            elif type(factor) == str:\n",
    "                name = factor\n",
    "                pattern = re.compile(factor, re.IGNORECASE)\n",
    "    \n",
    "            self.df['_matches'] = self.df['text_body'].apply(lambda x: \n",
    "                                                                      [(m.start(), m.group()) \n",
    "                                                                       for m in pattern.finditer(x)])\n",
    "            \n",
    "            self.df[name + '_count'] = self.df['_matches'].apply(lambda x: len(x))\n",
    "            self.df['has_' + name + '?'] = self.df[name + '_count'].apply(lambda x: x > 0)\n",
    "            self.df[name + '_in_title'] = self.df['title'].apply(lambda x:\n",
    "                                                                         len(pattern.findall(x)) > 0)\n",
    "            self.df[name + '_count'] = self.df.apply(lambda x:\n",
    "                                                             x[name + '_count'] + 10\n",
    "                                                            if x[name + '_in_title'] \n",
    "                                                             else x[name + '_count'],\n",
    "                                                            axis=1)\n",
    "            self.df['total_rank'] += self.weights['risk'] * self.df[name + '_count']\n",
    "            \n",
    "            self.df['risk_factors'] = self.df.apply(lambda x: \n",
    "                                    x['risk_factors'] + [name] if x['has_' + name + '?']\n",
    "                                    else x['risk_factors'],\n",
    "                                   axis=1)\n",
    "            self.df['match_indices'] = self.df.apply(lambda x: \n",
    "                                    x['match_indices'] + [n[0] for n in x['_matches']] if x['has_' + name + '?']\n",
    "                                    else x['match_indices'],\n",
    "                                   axis=1)\n",
    "            self.df.drop('_matches', axis=1, inplace=True)\n",
    "            \n",
    "\n",
    "    def analyze_designs(self, design_list):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for study designs and returns a report df \n",
    "        with 'design' and 'design_rank'. 'design_rank' is decided upon from the \n",
    "        input in crowdsourced medical dictionary.\n",
    "        \"\"\"\n",
    "        if design_list == None:\n",
    "            design_list = PaperAnalyzer.DEFAULT_DESIGNS\n",
    "        self.df['design'] = self.df['text_body'].progress_apply(lambda x:\n",
    "                                                                      [re.findall(des, x, re.IGNORECASE) \n",
    "                                                                       for des in design_list])\n",
    "        self.df['design_rank'] = self.df['design'].apply(lambda x:\n",
    "                                                                len(x))\n",
    "        self.df['design_rank'] += self.df['design'].apply(lambda x: rank_design(' '.join(flatten(x))))\n",
    "        self.df['total_rank'] += self.weights['design'] * self.df['design_rank']\n",
    "\n",
    "    def analyze_outcomes(self, outcomes):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for outcomes and returns a report df \n",
    "        with 'outcomes' and 'outcome_rank'. 'outcome_rank' is decided upon \n",
    "        by the frequency of mentions of outcomes in the excerpt\n",
    "        \"\"\"\n",
    "        \n",
    "        if outcomes == None:\n",
    "            outcomes = PaperAnalyzer.DEFAULT_OUTCOMES\n",
    "        self.df['outcomes'] = self.df['text_body'].progress_apply(lambda x:\n",
    "                                                                        [re.findall(outcome, x, re.IGNORECASE)\n",
    "                                                                         for outcome in outcomes])\n",
    "        self.df['outcome_rank'] = self.df['outcomes'].apply(lambda x: len(x))\n",
    "        self.df['total_rank'] += self.weights['outcome']* self.df['outcome_rank']\n",
    "        \n",
    "    def analyze_fatality(self, fatality_list):\n",
    "        \"\"\"\n",
    "        Analyses papers in self.df for information on fatality \n",
    "        returns a report df with 'fatality_rank'. \n",
    "        'fatality_rank' is decided upon by the frequency of \n",
    "        mentions of fatality in the excerpt\n",
    "        \"\"\"\n",
    "        \n",
    "        if fatality_list == None:\n",
    "            fatality_list = PaperAnalyzer.DEFAULT_FATAL\n",
    "        self.df['fatality_rank'] = self.df['text_body'].progress_apply(lambda x:\n",
    "                                                                        len([re.findall(key, x, re.IGNORECASE)\n",
    "                                                                         for key in fatality_list]))\n",
    "        self.df['has_fatality_info?'] = self.df['fatality_rank'].apply(lambda x: x > 0)\n",
    "        self.df['total_rank'] += self.weights['fatality']* self.df['fatality_rank']\n",
    "\n",
    "    def perform_analysis(self, risk_factors, design_list=None, outcomes=None, fatality_list = None):\n",
    "        \"\"\"\n",
    "        This function is a wrapper function that provides interface\n",
    "        to conduct analysis on all of risk factors, study designs and\n",
    "        outcomes. Users may specify their own design_list or outcomes. If not,\n",
    "        the default is used.\n",
    "        \"\"\"\n",
    "        print(\"Analyzing risks\")\n",
    "        self.analyze_risks(risk_factors)\n",
    "        print(\"Analyzing study designs\")\n",
    "        self.analyze_designs(design_list)\n",
    "        print(\"Analyzing outcomes\")\n",
    "        self.analyze_outcomes(outcomes)\n",
    "        print(\"Analyzing fatality\")\n",
    "        self.analyze_fatality(fatality_list)\n",
    "\n",
    "    def get_df(self, risk_factor=None):\n",
    "        \"\"\"\n",
    "        Applies section ratings, updates total ratings and returns reporting df\n",
    "            risk_factor: if specified, the returned df will only have excerpts\n",
    "                            that mention this risk factor\n",
    "        \"\"\"\n",
    "        self.df['section_rank'] = self.df['section'].apply(lambda x: self.section_ratings[x] \n",
    "                                                           if x in self.section_ratings else 5)\n",
    "        self.df['total_rank'] += self.df['section_rank']\n",
    "        \n",
    "        # Normalizing total rank for length of excerpts\n",
    "        self.df['total_rank'] = self.df.apply(lambda x: x['total_rank'] + \n",
    "                                                        (self.weights['inverse_length']/\n",
    "                                                         (len(word_tokenize(x['text_body'])))), \n",
    "                                              axis=1)\n",
    "        if risk_factor:\n",
    "            if not self.__ANALYZED_RISKS:\n",
    "                raise ValueError(self.__ERROR_MESSAGE)\n",
    "            return self.df[self.df['has_' + risk_factor + '?'] == True]\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c16c8eb935d4bb5b3bb28ab2e77aba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc25d0fcd99475581256b3e277c7529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440f845d4c254eeeae3dfe7ef1822359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a26b6aa3d74b349509146cffdef1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "covid_analysis = PaperAnalyzer(covid_df)\n",
    "covid_analysis.analyze_risks(risk_factors)\n",
    "covid_analysis.analyze_designs(design_list)\n",
    "covid_analysis.analyze_outcomes(outcome_list)\n",
    "covid_analysis.analyze_fatality(fatality_list)\n",
    "enriched_covid_df = covid_analysis.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 53)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pneumonia arising from any infectious etiology is an important cause of morbidity and mortality among pregnant women. It is the most prevalent non-obstetric infectious condition that occurs during pregnancy [14] [15] [16] . In one study pneumonia was the 3rd most common cause of indirect maternal death [17] . Approximately 25 percent of pregnant women who develop pneumonia will need to be hospitalized in critical care units and require ventilatory support [16] . Although bacterial pneumonia is a serious disease when it occurs in pregnant women, even when the agent(s) are susceptible to antibiotics, viral pneumonia has even higher levels of morbidity and mortality during pregnancy [18] . As with other infectious diseases, the normal maternal physiologic changes that accompany pregnancy-including altered cell-mediated immunity [19] and changes in pulmonary function-have been hypothesized to affect both susceptibility to and clinical severity of pneumonia [20] [21] [22] . This has been evident historically during previous epidemics. The case fatality rate (CFR) for pregnant women infected with influenza during the 1918-1919 pandemic was 27%-even higher when exposure occurred during the 3rd trimester and upwards of 50% if pneumonia supervened [23] . During the 1957-1958 Asian flu epidemic, 10% of all deaths occurred in pregnant women, and their CFR was twice as high as that of infected women who were not pregnant [24] . The most common adverse obstetrical outcomes associated with maternal pneumonias from all causes include This newly recognized coronavirus, producing a disease that has been termed COVID-19, is rapidly spreading throughout China, has crossed international borders to infect persons in neighboring countries, and humans infected by the virus are travelling via commercial airlines to other continents. It is certain that 2019-nCoV will infect women who are pregnant, leaving the question open as to whether the novel coronavirus will have a similar or different effect on them compared with SARS-CoV and MERS-CoV. In order to address the potential obstetrical outcomes of infection to both mother and infant, the present communication describes the current state of knowledge regarding the effects of other coronavirus infections in pregnancy.\\nPneumonia arising from any infectious etiology is an important cause of morbidity and mortality among pregnant women. It is the most prevalent non-obstetric infectious condition that occurs during pregnancy [14] [15] [16] . In one study pneumonia was the 3rd most common cause of indirect maternal death [17] . Approximately 25 percent of pregnant women who develop pneumonia will need to be hospitalized in critical care units and require ventilatory support [16] . Although bacterial pneumonia is a serious disease when it occurs in pregnant women, even when the agent(s) are susceptible to antibiotics, viral pneumonia has even higher levels of morbidity and mortality during pregnancy [18] . As with other infectious diseases, the normal maternal physiologic changes that accompany pregnancy-including altered cell-mediated immunity [19] and changes in pulmonary function-have been hypothesized to affect both susceptibility to and clinical severity of pneumonia [20] [21] [22] . This has been evident historically during previous epidemics. The case fatality rate (CFR) for pregnant women infected with influenza during the 1918-1919 pandemic was 27%-even higher when exposure occurred during the 3rd trimester and upwards of 50% if pneumonia supervened [23] . During the 1957-1958 Asian flu epidemic, 10% of all deaths occurred in pregnant women, and their CFR was twice as high as that of infected women who were not pregnant [24] . The most common adverse obstetrical outcomes associated with maternal pneumonias from all causes include premature rupture of membranes (PROM) and preterm labor (PTL), intrauterine fetal demise (IUFD), intrauterine growth restriction (IUGR), and neonatal death [14] [15] [16] .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_covid_df.sort_values(by='total_rank', ascending=False).iloc[6]['text_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df.to_json(\"../../enriched_covid_df.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This marks the end of phase 1. The resulting dataframe will be stored as a json to be served by the web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Search (Phase 2)\n",
    "We will extend the capabilities from the `PaperAnalyzer` class and attempt to answer some questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Question` class will decompose and resolve a question about risk factors.\n",
    "The result will then be piped to an instance of `PaperAnalyzer` to conduct similar analysis. Users will be able to specify their own list of outcomes. If not specified, the default set of outcomes will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    \"\"\"\n",
    "    The purpose of this class is to resolve a question for \n",
    "    keyword searching\n",
    "    \"\"\"\n",
    "    def __init__(self, question, design_list=None, outcomes=None):\n",
    "        \"\"\"\n",
    "        The constuctor does most of the method-calling for question resolution\n",
    "        \"\"\"\n",
    "        self.DESIGN_LIST = design_list\n",
    "        self.OUTCOMES = outcomes\n",
    "        self.RISK = question\n",
    "        self.risk_factors = None\n",
    "        self.design_list = None\n",
    "        self.outcome_list = None\n",
    "        self.__resolve_question()\n",
    "        if design_list:\n",
    "            self.__resolve_design()\n",
    "        if outcomes:\n",
    "            self.__resolve_outcomes()\n",
    "\n",
    "    def __question_tokenize(self, sent):\n",
    "        \"\"\"\n",
    "        Cleans the question string\n",
    "        \"\"\"\n",
    "        abbvr_pattern = re.compile('(e.g.|i.e.)')\n",
    "        sent = abbvr_pattern.sub('', sent)\n",
    "        remove_punct_dict = {key: \" \" for key in string.punctuation}\n",
    "        remove_punct_dict['.'] = ''\n",
    "        remove_punct = str.maketrans(remove_punct_dict)\n",
    "        sent = sent.translate(remove_punct)\n",
    "        return sent.replace('R', 'R0').replace('-', ' ')\n",
    "\n",
    "    def __resolve_question(self):\n",
    "        \"\"\"\n",
    "        stems and removes irreleavnt words from questions\n",
    "        to create keywords for keyword analysis\n",
    "        \"\"\"\n",
    "        subquestion = self.RISK\n",
    "        sub_q = self.__question_tokenize(subquestion)\n",
    "        keywords = set([\n",
    "            stemmer.stem(word) for word in word_tokenize(sub_q)\n",
    "            if word.lower() not in stop_words and 'cov' not in word.lower()\n",
    "            and word.lower().islower()  #This checks and removes numbers\n",
    "        ])\n",
    "        self.risk_factors = list(keywords)\n",
    "\n",
    "    def __resolve_design(self):\n",
    "        \"\"\"\n",
    "        Resolves study designs to allow for study-design evaluation\n",
    "        \"\"\"\n",
    "        design_keys = self.DESIGN_LIST.split(\",\")\n",
    "        self.design_list = list(set(design_keys))\n",
    "\n",
    "    def __resolve_outcomes(self):\n",
    "        \"\"\"\n",
    "        Resolves outcomes to allow for outcome evaluation\n",
    "        \"\"\"\n",
    "        outcome_keys = self.__question_tokenize(self.OUTCOMES)\n",
    "        outcome_keys = set([\n",
    "            stemmer.stem(word) for word in word_tokenize(outcome_keys)\n",
    "            if word.lower() not in stop_words\n",
    "            and word.lower().islower()  #This checks and removes numbers\n",
    "        ])\n",
    "        self.outcome_list = list(outcome_keys)\n",
    "\n",
    "    def get_keywords(self):\n",
    "        \"\"\"\n",
    "        Returns keywords from earlier methods\n",
    "        \"\"\"\n",
    "        result = {'risk': None, 'design': None, 'outcome': None}\n",
    "        result['risk'] = self.risk_factors\n",
    "        if self.design_list:\n",
    "            result['design'] = self.design_list\n",
    "        if self.outcome_list:\n",
    "            result['outcome'] = self.outcome_list\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_question(df, question):\n",
    "    \"\"\"\n",
    "    Function to take in a Question instance and a \n",
    "    dataframe with covid-excerpts to perform \n",
    "    evaluation and rankings on information relevancy\n",
    "    \"\"\"\n",
    "    reference_df = PaperAnalyzer(df)\n",
    "    keys = question.get_keywords()\n",
    "    reference_df.perform_analysis(keys['risk'], keys['design'],\n",
    "                                  keys['outcome'])\n",
    "    return reference_df.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be trying out the question answering pipeline now with a few questions from the aforementionned [medical dictionary](https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/edit#gid=1217643351)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_sheet(url, sheet_name):\n",
    "    response=requests.get(url=url)\n",
    "    sample_file = io.BytesIO(response.content)\n",
    "    df = pd.read_excel(sample_file, sheet_name = sheet_name)\n",
    "    return df\n",
    "\n",
    "dict_url = 'https://docs.google.com/spreadsheets/d/1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E/export?format=xlsx&id=1t2e3CHGxHJBiFgHeW0dfwtvCG4x0CDCzcTFX7yz9Z2E'\n",
    "questions_df = get_google_sheet(dict_url, 'sub.question.matching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Subquestion</th>\n",
       "      <th>Outcome.list</th>\n",
       "      <th>Differences.list</th>\n",
       "      <th>Design.list</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is known about transmission, incubation, ...</td>\n",
       "      <td>Range of incubation periods for the disease in...</td>\n",
       "      <td>Range of incubation periods for humans: genera...</td>\n",
       "      <td>incubation period</td>\n",
       "      <td>age.</td>\n",
       "      <td>contact tracing, survival analysis, time-to-ev...</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is known about transmission, incubation, ...</td>\n",
       "      <td>Range of incubation periods for the disease in...</td>\n",
       "      <td>Range of incubation periods for humans: by age...</td>\n",
       "      <td>incubation period, stratified by age group</td>\n",
       "      <td>age.</td>\n",
       "      <td>contact tracing, survival analysis, time-to-ev...</td>\n",
       "      <td>Notes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0  What is known about transmission, incubation, ...   \n",
       "1  What is known about transmission, incubation, ...   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Range of incubation periods for the disease in...   \n",
       "1  Range of incubation periods for the disease in...   \n",
       "\n",
       "                                         Subquestion  \\\n",
       "0  Range of incubation periods for humans: genera...   \n",
       "1  Range of incubation periods for humans: by age...   \n",
       "\n",
       "                                 Outcome.list Differences.list  \\\n",
       "0                           incubation period             age.   \n",
       "1  incubation period, stratified by age group             age.   \n",
       "\n",
       "                                         Design.list  \\\n",
       "0  contact tracing, survival analysis, time-to-ev...   \n",
       "1  contact tracing, survival analysis, time-to-ev...   \n",
       "\n",
       "                                               Notes  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4...  \n",
       "1                                              Notes  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is COVID-19 transmitted on droplets?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking a sample question for analysis\n",
    "ques = questions_df.iloc[127]['Subquestion']\n",
    "ques = sent_tokenize(ques)[0]\n",
    "ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'risk factor analysis, logistic regression, cross-sectional case-control, matched case-control, observational case series, time series analysis, survival analysis'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Designs recommended for sample question\n",
    "des = questions_df.iloc[127]['Design.list']\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'odds of COVID-19 acquisition by occupation, age group, PPE use, observed/self-reported risk behaviors (e.g., inappropriately lowering mask to speak, touching face, eating without washing hands)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outcomes recommended for sample question\n",
    "outc = questions_df.iloc[127]['Outcome.list']\n",
    "outc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing risks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e0a39d1539444b9258ebdbc91dd8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing study designs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b207627eb84244a0ff277ce6bb2256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=304.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing outcomes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bc3cee42804d4ebf03938b36f35c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=304.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing fatality\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286fae009d654d94a47d4894e33fef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=304.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "report_df = analyze_question(covid_df, Question(ques, des, outc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now look at the 5 most relevant excerpts to the question we picked earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all suspected and confirmed cases, droplet precautions should be implemented, at a minimum. Staff must wear the following items:\n",
      "• surgical mask • fluid-resistant long-sleeved gown • goggles or face shield • gloves 22\n",
      "----------------------------- \n",
      "\n",
      "The National Health Commission of China released a report on 27 January 2020 that stated that 2019-nCoV could be transmitted not only via respiratory droplets, but also via direct contact. 2019-nCoV has now spread nationally and worldwide, and due to the lack of data on the size and origins of the floating population of Wuhan, it has been difficult for the Chinese government to arrange real-time medical resources and implement effective public health interventions.\n",
      "----------------------------- \n",
      "\n",
      "Standard preventive measures, such as general ward ventilation management, hand hygiene, and correct usage of surgical face masks and caps, should be vigorously implemented. Latex gloves should be worn if necessary. Adequate protective measures for droplet, contact, and airborne isolation should be stressed. Personal protection may vary on a case-by-case basis.\n",
      "The consultation area should be well ventilated, with daily cleaning, and final disinfection.\n",
      "----------------------------- \n",
      "\n",
      "This cluster is composed of one imported case and 12 local cases, and was identified with its first case (the 3rd patient in the country) confirmed on Jan 26, 2020. Its first case is suspected to be an imported case from Wuhan, China, transmitting SARS-CoV-2 to the 6 th and 28 th confirmed cases in Korea, which resulted in secondary cases. No further cases have been added in this cluster since February 21, 2020.\n",
      "----------------------------- \n",
      "\n",
      "Clinical datas on COVID-19 infection in newborns are still very limited. Whether SARS-CoV-2 can transmit vertically through placenta and its short-term and long-term harm to offsprings is still unclear. Therefore, it is important to keep all the specimens of SARS-CoV-2 infected and suspected pregnant women and their newborns, including pharyngeal swabs, peripheral blood, placenta tissue after delivery, amniotic fluid, cord blood, newborn pharyngeal swabs and breast milk, for in-depth study and continuous follow-up observation of future generations.\n",
      "----------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(report_df.sort_values(by='total_rank', ascending = False).iloc[i]['text_body'])\n",
    "    print(\"-----------------------------\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv11568a5b709c405b925f37b6b0b6dbdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
