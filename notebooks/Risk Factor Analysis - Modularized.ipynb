{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.extend(['within', 'what', 'how'])\n",
    "root = '../../kaggle_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PaperLoader` class will load all papers for the challenge and provide an interface for us to obtain `Pandas Dataframes` to work with. The focus will be on:\n",
    "- Obtaining Paper title, Abstract, Body\n",
    "- Obtaining Authors, Journal of Publication, Publication Date and Publication Date\n",
    "- Obtaining journal ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperLoader():\n",
    "    \"\"\"\n",
    "    Initializes PaperLoader class to read all .json files from root_directory\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, no_bib=True):\n",
    "        self.ROOT_DIR = root_dir\n",
    "        self.JSON_FILES = glob.glob(f'{root}/**/*.json', recursive=True)\n",
    "        self.PAPERS_COLUMN = {\n",
    "                                \"doc_id\": [None],\n",
    "                                \"title\": [None],\n",
    "                                \"abstract\": [None],\n",
    "                                \"text_body\": [None]\n",
    "                                }\n",
    "        self.PAPERS_DF = None\n",
    "        self.NO_BIB = no_bib\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes sections with more than 5 URL/DOI/HTTP instances\n",
    "    \"\"\"\n",
    "    def __clean_bib(self, body_text):\n",
    "        merged_body = []\n",
    "        for segment in body_text:\n",
    "            if len(merged_body) > 0:\n",
    "                if merged_body[-1]['section'] == segment['section']:\n",
    "                    merged_body[-1]['text'] += '\\n' + segment['text']\n",
    "                    continue\n",
    "            merged_body.append(segment)\n",
    "            \n",
    "        merged_body = [segment for segment in merged_body \n",
    "                       if len(re.findall(\"(http|doi|www)\", segment['text'])) <= 4]\n",
    "        return merged_body\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from all json files in root_directory\n",
    "    Each json file represents a paper. \n",
    "    Features extracted are: doc_id, title, abstract, text_body\n",
    "    \"\"\"\n",
    "    def create_paper_df(self):\n",
    "        self.PAPERS_DF = pd.DataFrame.from_dict(self.PAPERS_COLUMN)\n",
    "    \n",
    "        for i in tqdm(range(len(self.JSON_FILES))):\n",
    "            file_name = self.JSON_FILES[i]\n",
    "            row = {x: None for x in self.PAPERS_COLUMN}\n",
    "\n",
    "            with open(file_name) as json_data:\n",
    "                data = json.load(json_data)\n",
    "            \n",
    "                doc_id = data['paper_id']\n",
    "                row['doc_id'] = doc_id\n",
    "                row['title'] = data['metadata']['title']\n",
    "\n",
    "                # Now need all of abstract. Put it all in\n",
    "                # a list then use str.join() to split it\n",
    "                # into paragraphs.\n",
    "\n",
    "                if ('abstract' not in data or 'body_text' not in data):\n",
    "                    continue\n",
    "                else:\n",
    "                    abstract_list = [abst['text'] for abst in data['abstract']]\n",
    "                    abstract = \"\\n \".join(abstract_list)\n",
    "\n",
    "                row['abstract'] = abstract\n",
    "\n",
    "                # And lastly the body of the text.\n",
    "                if self.NO_BIB:\n",
    "                    body_list = self.__clean_bib(data['body_text'])\n",
    "                else:\n",
    "                    body_list = [bt['text'] for bt in data['body_text']]\n",
    "                \n",
    "                \n",
    "                row['text_body'] = body_list\n",
    "\n",
    "\n",
    "                self.PAPERS_DF = self.PAPERS_DF.append(row, ignore_index=True)\n",
    "\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    Joins paper information with information on journal for paper,\n",
    "    authors, doi and published date\n",
    "    \"\"\"\n",
    "    def merge_metadata(self):\n",
    "        metadata_df = pd.read_csv(self.ROOT_DIR + 'metadata.csv')\n",
    "        metadata_df_for_join = metadata_df.loc[:, \n",
    "                                               ['sha', 'publish_time', 'authors', 'journal', 'doi']]\n",
    "        self.PAPERS_DF = self.PAPERS_DF.merge(metadata_df_for_join, \n",
    "                            left_on='doc_id', right_on='sha', how='inner')\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Joins paper information with information on journal ratings\n",
    "    Important column: H_Index\n",
    "    \"\"\"\n",
    "    def merge_journals(self):\n",
    "        journal_df = pd.read_csv(root + 'scimagoj_2018.csv', sep = ';')\n",
    "        papers_ratings_df = self.PAPERS_DF.merge(journal_df.loc[:,['Title', 'H index']], \n",
    "                           left_on='journal', right_on='Title', how='left')\n",
    "        papers_ratings_df = papers_ratings_df.drop(['sha', 'Title'], \n",
    "                                                   axis=1).reset_index(drop = True)\n",
    "        self.PAPERS_DF = papers_ratings_df\n",
    "\n",
    "    \n",
    "    def get_df(self):\n",
    "        self.PAPERS_DF = self.PAPERS_DF.dropna(subset=['abstract', 'text_body'])\n",
    "        return self.PAPERS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534ca5aa704b40e6b1874da5f9d423f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59311.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paper_loader = PaperLoader(root)\n",
    "paper_loader.create_paper_df()\n",
    "paper_loader.merge_metadata()\n",
    "paper_loader.merge_journals()\n",
    "papers_df = paper_loader.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13075</th>\n",
       "      <td>4ed70c27f14b7f9e6219fe605eae2b21a229f23c</td>\n",
       "      <td>Update on therapeutic options for Middle East ...</td>\n",
       "      <td></td>\n",
       "      <td>[{'text': 'The Middle East respiratory syndrom...</td>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>Al-Tawfiq, Jaffar A.; Memish, Ziad A.</td>\n",
       "      <td>Expert Rev Anti Infect Ther</td>\n",
       "      <td>10.1080/14787210.2017.1271712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13076</th>\n",
       "      <td>306ef95a3a91e13a93bcc37fb2c509b67c0b5640</td>\n",
       "      <td>A Novel Approach for a Novel Pathogen: using a...</td>\n",
       "      <td>Thousands of people in the United States have ...</td>\n",
       "      <td>[{'text': 'The 2019 novel coronavirus (SARS-Co...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...</td>\n",
       "      <td>Clin Infect Dis</td>\n",
       "      <td>10.1093/cid/ciaa256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         doc_id  \\\n",
       "13075  4ed70c27f14b7f9e6219fe605eae2b21a229f23c   \n",
       "13076  306ef95a3a91e13a93bcc37fb2c509b67c0b5640   \n",
       "\n",
       "                                                   title  \\\n",
       "13075  Update on therapeutic options for Middle East ...   \n",
       "13076  A Novel Approach for a Novel Pathogen: using a...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13075                                                      \n",
       "13076  Thousands of people in the United States have ...   \n",
       "\n",
       "                                               text_body publish_time  \\\n",
       "13075  [{'text': 'The Middle East respiratory syndrom...   2016-12-24   \n",
       "13076  [{'text': 'The 2019 novel coronavirus (SARS-Co...   2020-03-12   \n",
       "\n",
       "                                                 authors  \\\n",
       "13075              Al-Tawfiq, Jaffar A.; Memish, Ziad A.   \n",
       "13076  Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...   \n",
       "\n",
       "                           journal                            doi  H index  \n",
       "13075  Expert Rev Anti Infect Ther  10.1080/14787210.2017.1271712      NaN  \n",
       "13076              Clin Infect Dis            10.1093/cid/ciaa256      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for covid-19 related papers released after 2019\n",
    "There is a lot of noise in this dataset due to information about other strains of coronavirus so we will select only the papers that are related to Covid-19. \n",
    "\n",
    "\n",
    "Also, while the older papers may contain some important insight on the variance among the  different strains of coronavirus, for our purposes, we will only be looking at papers published on 2019 or later because that is when Covid-19 became popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `RelevantFilter` class will filter the `DataFrame` from `PaperLoader` and filter for covid-19 papers published on 2019 or later. \n",
    "We will need to supply a list of covid-related keywords to filter from to the `constructor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevantFilter():\n",
    "    \"\"\"\n",
    "    Takes a list of key-words that the other methods use\n",
    "    to filter for relevant papers\n",
    "    \"\"\"\n",
    "    def __init__(self, keywords, year = '2019'):\n",
    "        self.KEYWORDS = keywords\n",
    "        self.YEAR = year\n",
    "    \n",
    "    def extract_recent(self, df):\n",
    "        return df[df['publish_time'] >= self.YEAR]\n",
    "    \n",
    "    def filter_papers(self, df):\n",
    "        cov_titles = [title for title in df['title'] \n",
    "                         if any((re.search(key,title.lower())) \n",
    "                         for key in self.KEYWORDS)]\n",
    "        data = df[df['title'].isin(cov_titles)].reset_index(drop = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_list = [\n",
    "    'covid-19','covid 19','novel coronavi',\n",
    "    'cord-19','cord 19','2019-nCoV','cov_2',\n",
    "    '2019 ncov','2019 cov','wuhan coronavi',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_filter = RelevantFilter(cov_list, '2019')\n",
    "covid_df = covid_filter.filter_papers(papers_df)\n",
    "covid_df = covid_filter.extract_recent(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6495, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13076</th>\n",
       "      <td>306ef95a3a91e13a93bcc37fb2c509b67c0b5640</td>\n",
       "      <td>A Novel Approach for a Novel Pathogen: using a...</td>\n",
       "      <td>Thousands of people in the United States have ...</td>\n",
       "      <td>[{'text': 'The 2019 novel coronavirus (SARS-Co...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...</td>\n",
       "      <td>Clin Infect Dis</td>\n",
       "      <td>10.1093/cid/ciaa256</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         doc_id  \\\n",
       "13076  306ef95a3a91e13a93bcc37fb2c509b67c0b5640   \n",
       "\n",
       "                                                   title  \\\n",
       "13076  A Novel Approach for a Novel Pathogen: using a...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13076  Thousands of people in the United States have ...   \n",
       "\n",
       "                                               text_body publish_time  \\\n",
       "13076  [{'text': 'The 2019 novel coronavirus (SARS-Co...   2020-03-12   \n",
       "\n",
       "                                                 authors          journal  \\\n",
       "13076  Bryson-Cahn, Chloe; Duchin, Jeffrey; Makarewic...  Clin Infect Dis   \n",
       "\n",
       "                       doi  H index  \n",
       "13076  10.1093/cid/ciaa256      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A Novel Approach for a Novel Pathogen: using a home assessment team to evaluate patients for 2019 novel coronavirus (SARS-CoV-2)',\n",
       "       'A Precision Medicine Approach to Rhinitis Evaluation and Management'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.head(2)['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Design_list = [\n",
    "    'retrospective cohort', 'cross-sectional case-control',\n",
    "    'cross sectional case control', 'prevalence survey', 'systematic review ',\n",
    "    ' meta-analysis', ' meta analysis'\n",
    "    'matched case-control', 'matched case control', 'medical record review',\n",
    "    'observational case series', 'time series analysis',\n",
    "    'pseudo-randomized controlled trials',\n",
    "    'pseudo randomized controlled trial', 'randomized controlled trials',\n",
    "    'randomized controlled trial'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_risk = [\n",
    "    'diabete', 'age', 'neonat', 'elderly,', 'cancer', 'histori', 'sputum',\n",
    "    'stool', 'blood', 'urine', 'house', 'environmental', 'seasonal',\n",
    "    'comorbidit', ' immune deficiency', 'liver', 'smok', 'age decil', 'heart',\n",
    "    'lung', 'climate,', 'PPE use', 'touching face', 'immun', 'insur',\n",
    "    'compromis', 'pregnan', 'race', 'ethnic', 'hyperten', 'child', 'tubercul',\n",
    "    'mtb', 'tb', 'MTB', 'TB'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_outcom = ['risk','range','duration','asymptomatic',\n",
    " 'infecti', 'reproducti',  'route', \n",
    " 'age','transmm'\n",
    " 'stratifi',\n",
    " 'period,',\n",
    " 'health',\n",
    " 'r0','shedd', 'viral'\n",
    " 'period','incub',\n",
    " 'generat',\n",
    " 'factor',\n",
    " 'interval,',\n",
    " 'serial'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factors = [\n",
    "                        {\n",
    "                        'name': 'smoking',\n",
    "                        'pattern': 'smok'\n",
    "                        },\n",
    "                        {\n",
    "                        'name': 'diabetes',\n",
    "                        'pattern': 'diabete'\n",
    "                        },\n",
    "                        {\n",
    "                        'name': 'pregnancy',\n",
    "                        'pattern': 'pregnan'\n",
    "                        },\n",
    "                        {\n",
    "                        'name': 'tuberculosis',\n",
    "                        'pattern': '(tubercul|MTB|TB)'\n",
    "                        }\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_list = [\n",
    "    'mathemat', 'profil', 'cross sectional case control',\n",
    "    'matched case control', 'contact', 'surviv', 'tracing,', 'time to event',\n",
    "    'time-to-event', 'risk factor analysis', 'logistic regression',\n",
    "    'cross-sectional case-control', 'matched case-control',\n",
    "    'observational case series', 'time series analysis', 'survival analysis',\n",
    "    'investigati', 'model', 'outbreak', 'stochast', 'statist', 'analysi',\n",
    "    'experiment', 'excret', 'investig'\n",
    "    'retrospective cohort', 'cross-sectional case-control',\n",
    "    'cross sectional case control', 'prevalence survey', 'systematic review ',\n",
    "    'meta-analysis', 'meta analysis', 'matched case-control',\n",
    "    'matched case control', 'medical record review',\n",
    "    'observational case series', 'time series analysis',\n",
    "    'pseudo-randomized controlled', 'pseudo randomized controlled',\n",
    "    'randomized controlled', 'retrospective analysis', 'retrospective study',\n",
    "    'retrospective studies'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_list = [\n",
    "    'risk', 'range', 'duration', 'asymptomatic', 'infecti', 'reproducti',\n",
    "    'route', 'age', 'transmm'\n",
    "    'stratifi', 'period,', 'health', 'r0', 'shedd', 'viral'\n",
    "    'period', 'incub', 'generat', 'factor', 'interval,', 'serial'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PaperAnalyzer` \n",
    "Will be filled with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAnalyzer():\n",
    "    def __init__(self, parent_df):\n",
    "        self.working_df = parent_df\n",
    "        self.__ANALYZED_RISKS = False\n",
    "        self.__RISK_MESSAGE = \"Need to perform risk analyze first. Try calling self.analyze_risks()\"\n",
    "\n",
    "    def analyze_risks(self, risk_factors):\n",
    "        risk_temp_arr = []\n",
    "        for index, row in tqdm(self.working_df.iterrows(),\n",
    "                               total=self.working_df.shape[0]):\n",
    "            for section in row['text_body']:\n",
    "                section_row = row.copy()\n",
    "                section_row['section'] = section['section']\n",
    "                section_row['text_body'] = section['text']\n",
    "                body = section_row['text_body'].lower()\n",
    "\n",
    "                for factor in risk_factors:\n",
    "                    name = factor['name']\n",
    "                    matches = re.findall(factor['pattern'], body)\n",
    "                    section_row['has_' + name + '?'] = False\n",
    "                    section_row[name + '_count'] = 0\n",
    "                    section_row[name + '_in_title'] = False\n",
    "\n",
    "                    if len(matches) > 0:\n",
    "                        section_row['has_' + name + '?'] = True\n",
    "                        section_row[name + '_count'] = len(matches)\n",
    "                    if re.findall(factor['pattern'], section_row['title']):\n",
    "                        section_row[name + '_in_title'] = True\n",
    "                        # If the risk factor is in title of paper we reward with higher count\n",
    "                        section_row[name + '_count'] += 10\n",
    "\n",
    "            risk_temp_arr.append(section_row)\n",
    "\n",
    "        self.working_df = pd.DataFrame(risk_temp_arr)\n",
    "        self.__ANALYZED_RISKS = True\n",
    "\n",
    "    def analyze_designs(self, design_list):\n",
    "        if not self.__ANALYZED_RISKS:\n",
    "            raise ValueError(self.__ERROR_MESSAGE)\n",
    "\n",
    "        design_temp_arr = []\n",
    "        for index, row in tqdm(self.working_df.iterrows(),\n",
    "                               total=self.working_df.shape[0]):\n",
    "            design_matches = [\n",
    "                re.findall(des, row['text_body']) for des in design_list\n",
    "            ]\n",
    "            design_matches = np.concatenate(design_matches)\n",
    "            design_rank = 0\n",
    "            if len(design_matches) > 0:\n",
    "                if ('meta-analysis' or 'meta analysis') in design_matches:\n",
    "                    design_rank = 6\n",
    "                if ('randomized controlled') in design_matches:\n",
    "                    design_rank = 5\n",
    "                if ('pseudo-randomized controlled'\n",
    "                        or 'pseudo randomized controlled') in design_matches:\n",
    "                    design_rank = 4\n",
    "                design_rank = design_rank + len(design_matches)\n",
    "            row['design_matches'] = design_matches\n",
    "            row['design_rank'] = design_rank\n",
    "            design_temp_arr.append(row)\n",
    "\n",
    "        self.working_df = pd.DataFrame(design_temp_arr)\n",
    "\n",
    "    def analyze_outcomes(self, outcomes):\n",
    "        if not self.__ANALYZED_RISKS:\n",
    "            raise ValueError(self.__ERROR_MESSAGE)\n",
    "\n",
    "        outcome_arr = []\n",
    "        for index, row in tqdm(self.working_df.iterrows(),\n",
    "                               total=self.working_df.shape[0]):\n",
    "\n",
    "            outcome_matches = [\n",
    "                re.findall(outcome, row['text_body']) for outcome in outcomes\n",
    "            ]\n",
    "            outcome_matches = np.concatenate(outcome_matches)\n",
    "            outcome_rank = 0\n",
    "            outcome_rank = len(outcome_matches)\n",
    "\n",
    "            row['outcome_matches'] = outcome_matches\n",
    "            row['outcome_rank'] = outcome_rank\n",
    "\n",
    "            outcome_arr.append(row)\n",
    "\n",
    "        self.working_df = pd.DataFrame(outcome_arr)\n",
    "\n",
    "    def perform_analysis(self, risk_factors, design_list, outcomes):\n",
    "        print(\"Analyzing risks\")\n",
    "        self.analyze_risks(risk_factors)\n",
    "        print(\"Analyzing study designs\")\n",
    "        self.analyze_designs(design_list)\n",
    "        print(\"Analyzing outcomes\")\n",
    "        self.analyze_outcomes(outcomes)\n",
    "        \n",
    "    \n",
    "    def question_analysis(self, question):\n",
    "        keywords = []\n",
    "        # resolve questions into keywords of risk factors\n",
    "        ####\n",
    "        \n",
    "        self.analyze_risks(keywords)\n",
    "        \n",
    "        \n",
    "        if design_list:\n",
    "            self.analyze_design(design_list)        \n",
    "        if outcomes:\n",
    "            self.analyze_outcomes(outcomes)\n",
    "\n",
    "    def get_df(self, risk_factor=None):\n",
    "        if risk_factor:\n",
    "            if not self.__ANALYZED_RISKS:\n",
    "                raise ValueError(self.__ERROR_MESSAGE)\n",
    "            return self.working_df[self_working_df['has_' + risk_factor +\n",
    "                                                   '?'] == True]\n",
    "        return self.working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206d1f4ff0df43358556f41922ba32db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "covid_analysis = PaperAnalyzer(covid_df)\n",
    "covid_analysis.analyze_risks(risk_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a79f7bac696440bbac3000639ad3884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "covid_analysis.analyze_designs(design_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad15bb3c007841fea219535226776eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "covid_analysis.analyze_outcomes(outcome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df = covid_analysis.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_covid_df.to_json(\"../../enriched_covid_df.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Question`\n",
    "Will be filled with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    def __init__(self, question, design_list = None, outcomes = None):\n",
    "        self.DESIGN_LIST = design_list\n",
    "        self.OUTCOMES = outcomes\n",
    "        self.QUESTION = question\n",
    "        self.__resolve_question()\n",
    "        if design_list:\n",
    "            self.__resolve_design()\n",
    "        if outcomes:\n",
    "            self.__resolve_outcomes()\n",
    "            \n",
    "    def __resolve_question(self):\n",
    "        questions = sent_tokenize(self.QUESTION)\n",
    "        for question in subquestion\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_document = pd.read_csv('../../../Downloads/Kaggle COVID-19 medical dictionary - sub.question.matching.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = question_document.iloc[127]['Subquestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = sent_tokenize(sample_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = [sent.replace('?', \" \") for sent in sample_q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is COVID-19 transmitted on droplets ',\n",
       " 'Is fecal-oral transmission a significant factor in person-to-person spread ',\n",
       " 'Is COVID-19 clustering in households (i.e., household environmental transmission) ',\n",
       " 'Is COVID-19 transmitted on aerosols ',\n",
       " 'What behavioral risk factors impact these transmission routes (e.g., hand-to-mouth action in small children) ']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in sample_q:\n",
    "    subquestion = list(set(\n",
    "        [stemmer.stem(word) for word in word_tokenize(question)\n",
    "        if word.lower() not in stop_words]\n",
    "    ))\n",
    "    question_list.append(question, process_question(subquestion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['transmit', 'covid-19', 'droplet'],\n",
       " ['signific', 'fecal-or', 'factor', 'transmiss', 'spread', 'person-to-person'],\n",
       " ['transmiss',\n",
       "  'cluster',\n",
       "  'covid-19',\n",
       "  ')',\n",
       "  'household',\n",
       "  '(',\n",
       "  'environment',\n",
       "  ',',\n",
       "  'i.e.'],\n",
       " ['aerosol', 'transmit', 'covid-19'],\n",
       " ['behavior',\n",
       "  'small',\n",
       "  'action',\n",
       "  'factor',\n",
       "  'impact',\n",
       "  'transmiss',\n",
       "  'rout',\n",
       "  'hand-to-mouth',\n",
       "  'risk',\n",
       "  ')',\n",
       "  '(',\n",
       "  'e.g.',\n",
       "  ',',\n",
       "  'children']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv11568a5b709c405b925f37b6b0b6dbdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
