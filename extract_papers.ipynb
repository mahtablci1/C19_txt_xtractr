{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "The objective of the notebook is to obtain a `csv` file named `papers_df.csv` that will contain the following information for each paper:\n",
    "- Title\n",
    "- DOI\n",
    "- Abstract\n",
    "- Body\n",
    "- Journal\n",
    "- Journal Rating(H Index)\n",
    "- Authors\n",
    "- Date Published\n",
    "\n",
    "\n",
    "Note: The `doc_id` column will the key to stitch different tables together to obtain aforementionned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#relevant imports\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PaperLoader` class will load all papers for the challenge and provide an interface for us to obtain `Pandas Dataframes` to work with. The focus will be on:\n",
    "- Obtaining Paper title, Abstract, Body\n",
    "- Obtaining Authors, Journal of Publication, Publication Date and Publication Date\n",
    "- Obtaining journal ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperLoader():\n",
    "    \"\"\"\n",
    "    Initializes PaperLoader class to read all .json files from root_directory\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir):\n",
    "        self.ROOT_DIR = root_dir\n",
    "        self.JSON_FILES = glob.glob(f'{root}/**/*.json', recursive=True)\n",
    "        self.PAPERS_COLUMN = {\n",
    "                                \"doc_id\": [None],\n",
    "                                \"title\": [None],\n",
    "                                \"abstract\": [None],\n",
    "                                \"text_body\": [None]\n",
    "                                }\n",
    "        self.PAPERS_DF = None\n",
    "        \n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from all json files in root_directory\n",
    "    Each json file represents a paper. \n",
    "    Features extracted are: doc_id, title, abstract, text_body\n",
    "    \"\"\"\n",
    "    def createPaperDf(self):\n",
    "        self.PAPERS_DF = pd.DataFrame.from_dict(self.PAPERS_COLUMN)\n",
    "    \n",
    "        for file_name in self.JSON_FILES:\n",
    "\n",
    "            row = {x: None for x in self.PAPERS_COLUMN}\n",
    "\n",
    "            with open(file_name) as json_data:\n",
    "                data = json.load(json_data)\n",
    "\n",
    "                doc_id = data['paper_id']\n",
    "                row['doc_id'] = doc_id\n",
    "                row['title'] = data['metadata']['title']\n",
    "\n",
    "                # Now need all of abstract. Put it all in\n",
    "                # a list then use str.join() to split it\n",
    "                # into paragraphs.\n",
    "\n",
    "                abstract_list = [abst['text'] for abst in data['abstract']]\n",
    "                abstract = \"\\n \".join(abstract_list)\n",
    "\n",
    "                row['abstract'] = abstract\n",
    "\n",
    "                # And lastly the body of the text.\n",
    "                body_list = [bt['text'] for bt in data['body_text']]\n",
    "                body = \"\\n \".join(body_list)\n",
    "\n",
    "                row['text_body'] = body\n",
    "\n",
    "\n",
    "                self.PAPERS_DF = self.PAPERS_DF.append(row, ignore_index=True)\n",
    "        return self.PAPERS_DF\n",
    "    \n",
    "    \"\"\"\n",
    "    Joins paper information with information on journal for paper,\n",
    "    authors, doi and published date\n",
    "    \"\"\"\n",
    "    def mergeMetadata(self):\n",
    "        metadata_df = pd.read_csv(self.ROOT_DIR + 'metadata.csv')\n",
    "        metadata_df_for_join = metadata_df.loc[:, \n",
    "                                               ['sha', 'publish_time', 'authors', 'journal', 'doi']]\n",
    "        self.PAPERS_DF = self.PAPERS_DF.merge(metadata_df_for_join, \n",
    "                            left_on='doc_id', right_on='sha', how='inner')\n",
    "        return self.PAPERS_DF\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Joins paper information with information on journal ratings\n",
    "    Important column: H_Index\n",
    "    \"\"\"\n",
    "    def mergeJournals(self):\n",
    "        journal_df = pd.read_csv(root + '../scimagoj_2018.csv', sep = ';')\n",
    "        papers_ratings_df = self.PAPERS_DF.merge(journal_df.loc[:,['Title', 'H index']], \n",
    "                           left_on='journal', right_on='Title', how='left')\n",
    "        papers_ratings_df = papers_ratings_df.dropna(subset = ['abstract', 'text_body'])\n",
    "        papers_ratings_df = papers_ratings_df.drop(['sha', 'Title'], \n",
    "                                                   axis=1).reset_index(drop = True)\n",
    "        self.PAPERS_DF = papers_ratings_df\n",
    "        \n",
    "        return self.PAPERS_DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/corona_challenge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_loader = PaperLoader(root)\n",
    "paper_loader.createPaperDf()\n",
    "paper_loader.mergeMetadata()\n",
    "paper_loader.mergeJournals()\n",
    "papers_df = paper_loader.PAPERS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>doi</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 24...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to VP...</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>Joseph C. Ward; Lidia Lasecka-Dykes; Chris Nei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1101/2020.01.10.901801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>During the past three months, a new coronaviru...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-Co...</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>Carla Mavian; Simone Marini; Costanza Manes; I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1101/2020.03.16.20034470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doc_id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "\n",
       "                                               title  \\\n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...   \n",
       "1  Analysis Title: Regaining perspective on SARS-...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  word count: 194 22 Text word count: 5168 23 24...   \n",
       "1  During the past three months, a new coronaviru...   \n",
       "\n",
       "                                           text_body publish_time  \\\n",
       "0  VP3, and VP0 (which is further processed to VP...   2020-01-11   \n",
       "1  In December 2019, a novel coronavirus, SARS-Co...   2020-03-20   \n",
       "\n",
       "                                             authors journal  \\\n",
       "0  Joseph C. Ward; Lidia Lasecka-Dykes; Chris Nei...     NaN   \n",
       "1  Carla Mavian; Simone Marini; Costanza Manes; I...     NaN   \n",
       "\n",
       "                           doi  H index  \n",
       "0    10.1101/2020.01.10.901801      NaN  \n",
       "1  10.1101/2020.03.16.20034470      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.to_csv('output/papers_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering papers for transmission details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_keywords = [\n",
    "    'transmi', 'sneez', 'contact trac', 'reproduc', 'environ'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_keywords = [\n",
    "    'smok', 'pulm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact copy of Maria's function\n",
    "abstracts = list(df_smoke['abstract'])\n",
    "df_smoke['transmission_indicator'] = df_smoke['abstract'].apply(lambda x: \n",
    "                                                                any(keyword in x for \n",
    "                                                                    keyword in transmission_keywords))\n",
    "df_smoke['smoke_indicator'] = df_smoke['abstract'].apply(lambda x: \n",
    "                                                                any(keyword in x for \n",
    "                                                                    keyword in smoke_keywords))\n",
    "transmission_df = df_smoke[df_smoke['transmission_indicator'] == True].reset_index(drop = True)\n",
    "smoke_df = df_smoke[df_smoke['smoke_indicator'] == True].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_df.shape, smoke_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_df.to_csv('transmission_df.csv')\n",
    "smoke_df.to_csv('smoke_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_colab_df = transmission_df.sort_values(by = 'H index', ascending = False).reset_index(drop = True)\n",
    "transmission_colab_df = transmission_colab_df.iloc[0:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_colab_df = smoke_df.sort_values(by = 'H index', ascending = False).reset_index(drop = True)\n",
    "smoke_colab_df = smoke_colab_df.iloc[0:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_colab_df.to_csv('transmission_colab_df.csv')\n",
    "smoke_colab_df.to_csv('smoke_colab_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
